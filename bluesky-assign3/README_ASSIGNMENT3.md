# Assignment 3: Online Recruitment Fraud Detection Labeler

Group Number: Group 14

Group Members: Jiayu Zhang (jz2344), Xinyi Huang (xh453), Eva Huang (lh764), Grace Myers (gm586)

## Description of files
- train_model.py: Training script. Reads labeled text from `cleaned_training_data.csv`, creates a stratified train/test split, trains TF‑IDF + Logistic Regression, and saves artifacts and split CSVs.
- test_model.py: Offline evaluator. Loads saved artifacts and evaluates only the held‑out test set. Prints overall Accuracy, Precision, Recall, F1, a classification report, and a few example posts (TP/TN/FP/FN categories).
- data/cleaned_training_data.csv: Labeled dataset used for training and creating the held‑out test split. Columns: `text`, `label` (0=legit, 1=suspicious, 2=fraudulent).
- data/train_test_split_indices.csv: Generated by training; indicates which row indices belong to `train` vs `test`.
- data/train_set.csv / data/test_set.csv: Generated by training; the explicit records for each split.
- requirements.txt: Python dependencies for this project.
- README_ASSIGNMENT3.md: This file with group details, file descriptions, and run instructions.

## How to run
1) Create env and install deps
```bash
cd /bluesky-assign3
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

2) Train (example: binary, 75% train split; artifacts and split CSVs will be created)
Flags/options and how to use them:
- `--data`: Path to the labeled CSV. Default: `cleaned_training_data.csv`.
- `--out_dir`: Directory to write artifacts and split CSVs. Default: current directory (`.`).
- `--data_used_for_training`: Fraction in (0,1). If provided, a stratified random sample of that fraction is used as the training set; the remainder becomes the test set. Example: `--data_used_for_training 0.75`.
- `--binary`: Collapse labels {1,2} into a single positive class (recruitment‑risk) vs. 0 (legit). Omit to train 3‑class.

How the split works:
- If `--data_used_for_training <fraction>` is specified, we perform a stratified random split with the given fraction for training and the rest for testing (ensuring at least one row in each split). If not specified, the default fraction is 0.75 (75% train / 25% test).
- The split membership is saved to `train_test_split_indices.csv` and the explicit rows are written to `train_set.csv` and `test_set.csv`. The tester (`test_model.py`) uses these to ensure test evaluation contains no training rows.
```bash
python train_model.py --data data/cleaned_training_data.csv --out_dir . --data_used_for_training 0.75 --binary
```
Notes:
- The training script reports training‑set performance only (accuracy, precision, recall, F1 on the training split).
- Artifacts produced: `model_files/vectorizer.pkl`, `model_files/fraud_model.pkl`, `data/train_test_split_indices.csv`, `data/train_set.csv`, `data/test_set.csv`.

3) Test (evaluate ONLY on the held‑out test set)
```bash
python test_model.py --data data/test_set.csv --binary
```
The test report prints:
- “TEST SET PERFORMANCE … (no training data is present)”
- Overall Accuracy, Precision, Recall, F1
- Full classification report (binary or 3‑class)
- 2–3 qualitative examples for each: correct SAFE, correct SCAM, false negative, false positive


## End-to-end overview
1) Get data, clean data
- Source: `cleaned_training_data.csv` with columns `text` and integer `label` (0=legit, 1=suspicious, 2=fraudulent).
- Basic cleaning enforced by code: missing/NaN `text` dropped, labels cast to int; script validates required columns.
- After training, the split is saved to `train_test_split_indices.csv` and explicit `train_set.csv` / `test_set.csv` files for reproducibility.
  - These are written under `data/` by default.

2) Train model (flags control behavior)
- Run `train_model.py` with:
  - `--data`: input CSV path (default: `data/cleaned_training_data.csv`)
  - `--out_dir`: where to save artifacts (default: `.`; writes to `model_files/` and `data/`)
  - `--data_used_for_training <fraction in (0,1)>`: fraction for training (stratified); remainder becomes test. Defaults to 0.75 if omitted.
  - `--binary`: collapse labels {1,2} → 1 (recruitment‑risk), 0 stays legit; omit to train 3‑class.
- Outputs: `model_files/vectorizer.pkl`, `model_files/fraud_model.pkl`, `data/train_test_split_indices.csv`, `data/train_set.csv`, `data/test_set.csv`.
- Prints training‑set performance only (accuracy, precision, recall, F1 on training split).

3) Test model (flags control evaluation mode)
- Run `test_model.py` with:
  - `--data data/test_set.csv` (fast path) or `--data data/cleaned_training_data.csv` (auto-filter to test indices).
  - `--binary` to evaluate as 2‑tier risk vs legit; omit for 3‑class.
- Enforces test‑only evaluation (no training rows). Reports overall Accuracy, Precision, Recall, F1 and a classification report.

4) Diagnostics and results
- Prints short text previews for qualitative examples: true negatives/positives and false negatives/positives (2–3 each).
- Use these examples to refine labels, add hard negatives/positives, or adjust features/thresholds.
- Artifacts are versionable locally (pickles are ignored by git per `.gitignore`) and can be regenerated deterministically from the same CSV and flags.
